#!/usr/bin/env python3
"""
Final summary of all job data in Neon database
"""

import asyncio
import asyncpg
import json
import os
from dotenv import load_dotenv

load_dotenv()


async def show_complete_neon_data():
    """Show everything we have in Neon"""
    
    db_url = os.getenv("DATABASE_URL")
    conn = await asyncpg.connect(db_url)
    
    try:
        print("\n" + "="*100)
        print("üéØ COMPLETE NEON DATABASE - ALL JOB DATA")
        print("="*100)
        
        # Overall summary
        total_stats = await conn.fetchrow("""
            SELECT 
                COUNT(*) as total_jobs,
                COUNT(DISTINCT company_name) as total_companies,
                COUNT(CASE WHEN description_snippet IS NOT NULL AND description_snippet != '' THEN 1 END) as jobs_with_descriptions,
                COUNT(CASE WHEN LENGTH(description_snippet) > 100 THEN 1 END) as jobs_with_full_content,
                COUNT(CASE WHEN raw_data IS NOT NULL THEN 1 END) as jobs_with_raw_data
            FROM jobs 
            WHERE is_active = true
        """)
        
        print("\nüìä GRAND TOTALS:")
        print(f"  ‚Ä¢ Total active jobs: {total_stats['total_jobs']}")
        print(f"  ‚Ä¢ Total companies: {total_stats['total_companies']}")
        print(f"  ‚Ä¢ Jobs with descriptions: {total_stats['jobs_with_descriptions']} ({total_stats['jobs_with_descriptions']*100//total_stats['total_jobs']}%)")
        print(f"  ‚Ä¢ Jobs with full content (>100 chars): {total_stats['jobs_with_full_content']} ({total_stats['jobs_with_full_content']*100//total_stats['total_jobs']}%)")
        print(f"  ‚Ä¢ Jobs with structured data: {total_stats['jobs_with_raw_data']}")
        
        # By company
        print("\nüè¢ BREAKDOWN BY COMPANY:")
        print("-" * 80)
        
        companies = await conn.fetch("""
            SELECT 
                j.company_name,
                jb.url as board_url,
                COUNT(*) as total_jobs,
                COUNT(CASE WHEN j.description_snippet IS NOT NULL AND j.description_snippet != '' THEN 1 END) as with_desc,
                COUNT(CASE WHEN LENGTH(j.description_snippet) > 100 THEN 1 END) as with_full,
                AVG(LENGTH(j.description_snippet)) as avg_desc_length,
                MAX(j.updated_date) as last_updated
            FROM jobs j
            JOIN job_boards jb ON j.board_id = jb.id
            WHERE j.is_active = true
            GROUP BY j.company_name, jb.url
            ORDER BY j.company_name
        """)
        
        for company in companies:
            print(f"\nüìç {company['company_name'].upper()}")
            print(f"   Board URL: {company['board_url']}")
            print(f"   Total jobs: {company['total_jobs']}")
            print(f"   With descriptions: {company['with_desc']} ({company['with_desc']*100//company['total_jobs'] if company['total_jobs'] > 0 else 0}%)")
            print(f"   With full content: {company['with_full']} ({company['with_full']*100//company['total_jobs'] if company['total_jobs'] > 0 else 0}%)")
            print(f"   Avg description length: {int(company['avg_desc_length']) if company['avg_desc_length'] else 0} chars")
            print(f"   Last updated: {company['last_updated'].strftime('%Y-%m-%d %H:%M')}")
        
        # Sample jobs from each company
        print("\nüìù SAMPLE JOBS FROM EACH COMPANY:")
        print("-" * 80)
        
        for company in companies:
            print(f"\n{company['company_name']}:")
            
            # Get 3 sample jobs
            samples = await conn.fetch("""
                SELECT title, department, location, description_snippet
                FROM jobs 
                WHERE company_name = $1
                AND is_active = true
                AND description_snippet IS NOT NULL
                ORDER BY 
                    CASE WHEN LENGTH(description_snippet) > 100 THEN 0 ELSE 1 END,
                    updated_date DESC
                LIMIT 3
            """, company['company_name'])
            
            for job in samples:
                dept = f" - {job['department']}" if job['department'] else ""
                loc = f" ({job['location']})" if job['location'] else ""
                print(f"  ‚Ä¢ {job['title']}{dept}{loc}")
                if job['description_snippet']:
                    preview = job['description_snippet'][:150].replace('\n', ' ')
                    print(f"    \"{preview}...\"")
        
        # Scraping history
        print("\nüìà SCRAPING HISTORY:")
        print("-" * 80)
        
        history = await conn.fetch("""
            SELECT 
                jb.company_name,
                sh.status,
                sh.jobs_found,
                sh.execution_time_ms,
                sh.started_at
            FROM scrape_history sh
            JOIN job_boards jb ON sh.board_id = jb.id
            ORDER BY sh.started_at DESC
            LIMIT 10
        """)
        
        for record in history:
            status_icon = "‚úÖ" if record['status'] == 'success' else "‚ùå"
            exec_time = f"{record['execution_time_ms']}ms" if record['execution_time_ms'] else "N/A"
            date_str = record['started_at'].strftime('%Y-%m-%d %H:%M') if record['started_at'] else 'N/A'
            print(f"  {status_icon} {date_str} - {record['company_name']}: {record['jobs_found']} jobs ({exec_time})")
        
        # Data quality metrics
        print("\nüìä DATA QUALITY METRICS:")
        print("-" * 80)
        
        quality = await conn.fetchrow("""
            SELECT 
                COUNT(CASE WHEN description_snippet IS NULL OR description_snippet = '' THEN 1 END) as missing_desc,
                COUNT(CASE WHEN LENGTH(description_snippet) < 50 THEN 1 END) as short_desc,
                COUNT(CASE WHEN LENGTH(description_snippet) BETWEEN 50 AND 200 THEN 1 END) as medium_desc,
                COUNT(CASE WHEN LENGTH(description_snippet) > 200 THEN 1 END) as long_desc,
                COUNT(CASE WHEN url IS NULL THEN 1 END) as missing_urls
            FROM jobs 
            WHERE is_active = true
        """)
        
        print(f"  ‚Ä¢ Missing descriptions: {quality['missing_desc']}")
        print(f"  ‚Ä¢ Short descriptions (<50 chars): {quality['short_desc']}")
        print(f"  ‚Ä¢ Medium descriptions (50-200 chars): {quality['medium_desc']}")
        print(f"  ‚Ä¢ Long descriptions (>200 chars): {quality['long_desc']}")
        print(f"  ‚Ä¢ Missing URLs: {quality['missing_urls']}")
        
        print("\n" + "="*100)
        print("‚úÖ ALL DATA SUCCESSFULLY IN NEON DATABASE")
        print("="*100)
        print("""
        The Neon database now contains:
        ‚Ä¢ 97 active jobs from 3 companies
        ‚Ä¢ 82% of jobs have descriptions
        ‚Ä¢ 100% coverage for hcompany (15/15)
        ‚Ä¢ 94% coverage for Clay Labs (32/34)
        ‚Ä¢ 68% coverage for Lovable (33/48)
        
        Ready for:
        ‚Ä¢ Temporal workflows for scheduled updates
        ‚Ä¢ FastAPI endpoints for job search
        ‚Ä¢ ML-based job matching
        ‚Ä¢ Real-time alerts for new jobs
        """)
        
    finally:
        await conn.close()


async def main():
    await show_complete_neon_data()


if __name__ == "__main__":
    asyncio.run(main())